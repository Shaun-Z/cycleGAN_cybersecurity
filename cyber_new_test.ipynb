{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from unet.unet_model import *\n",
    "from models import *\n",
    "from datasets import *\n",
    "from utils import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from dataset.time_dataset import NewTsDataset\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dtw import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is:  torch.Size([33, 1, 576]) torch.Size([33, 1, 576])\n"
     ]
    }
   ],
   "source": [
    "# Dataset loader\n",
    "datapath = Path('data')\n",
    "dataset = NewTsDataset(datapath/'CaseI-Attacks without any change.csv')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                                        shuffle=True, num_workers=4)\n",
    "print(\"The size of the dataset is: \", dataset.data_normal.size(), dataset.data_abnormal.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 576, 1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_feature_len = dataset.data_normal.size(2)\n",
    "abnormal_feature_len = dataset.data_abnormal.size(2)\n",
    "normal_seq_len = dataset.data_normal.size(1)\n",
    "abnormal_seq_len = dataset.data_abnormal.size(1)\n",
    "normal_feature_len, abnormal_feature_len, normal_seq_len, abnormal_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AB = LSTMUnetGenerator(33, normal_seq_len, normal_feature_len)\n",
    "G_BA = LSTMUnetGenerator(33, abnormal_seq_len, abnormal_feature_len)\n",
    "D_A = LSTMDiscriminator(normal_feature_len)\n",
    "D_B = LSTMDiscriminator(abnormal_feature_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.load_state_dict(torch.load(\"saved_models/cyber_new/G_AB_190.pth\"))\n",
    "G_BA.load_state_dict(torch.load(\"saved_models/cyber_new/G_BA_190.pth\"))\n",
    "D_A.load_state_dict(torch.load(\"saved_models/cyber_new/D_A_190.pth\"))\n",
    "D_B.load_state_dict(torch.load(\"saved_models/cyber_new/D_B_190.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMDiscriminator(\n",
       "  (lstm): LSTM(576, 256, batch_first=True)\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.eval()\n",
    "G_BA.eval()\n",
    "D_A.eval()\n",
    "D_B.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 576])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_normal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 144])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = NewTsDataset(datapath/'CaseII.csv')\n",
    "dataset_test.data_normal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 576])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.data_normal.repeat(1, 1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 1, 576])\n"
     ]
    }
   ],
   "source": [
    "# Assuming dataset_test.data_normal.repeat(1, 1, 4) is the tensor you want to add noise to\n",
    "noisy_tensor = dataset_test.data_normal.repeat(1, 1, 4) + torch.randn(dataset_test.data_normal.repeat(1, 1, 4).shape)\n",
    "\n",
    "# Print the shape of the noisy tensor\n",
    "print(noisy_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 1, 576]), torch.Size([33, 1, 576]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = G_AB(noisy_tensor)\n",
    "output_back = G_BA(output)\n",
    "output.shape, output_back.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([33, 1, 576]) \t Output Back size: torch.Size([33, 1, 576])\n",
      "- 8.77335820515503\n",
      "- 8.248511232425786\n",
      "- 8.649096214490402\n",
      "- 9.240148102431487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     15\u001b[0m dist1, cost, acc, path \u001b[38;5;241m=\u001b[39m dtw(output[i,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dataset_test\u001b[38;5;241m.\u001b[39mdata_normal[i,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, y: np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m-\u001b[39m y, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 16\u001b[0m dist2, cost, acc, path \u001b[38;5;241m=\u001b[39m \u001b[43mdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_back\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m dist3, cost, acc, path \u001b[38;5;241m=\u001b[39m dtw(output_back[i,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dataset_test\u001b[38;5;241m.\u001b[39mdata_normal[i,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, y: np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m-\u001b[39m y, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     18\u001b[0m res \u001b[38;5;241m=\u001b[39m (dist2\u001b[38;5;241m+\u001b[39mdist3)\u001b[38;5;241m/\u001b[39mdist1\n",
      "File \u001b[1;32me:\\projects\\dtw\\dtw\\dtw.py:47\u001b[0m, in \u001b[0;36mdtw\u001b[1;34m(x, y, dist, warp, w, s)\u001b[0m\n\u001b[0;32m     45\u001b[0m             i_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m k, r)\n\u001b[0;32m     46\u001b[0m             j_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(j \u001b[38;5;241m+\u001b[39m k, c)\n\u001b[1;32m---> 47\u001b[0m             min_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [D0[i_k, j] \u001b[38;5;241m*\u001b[39m s, D0[i, j_k] \u001b[38;5;241m*\u001b[39m s]\n\u001b[0;32m     48\u001b[0m         D1[i, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(min_list)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = G_AB(dataset_test.data_normal.repeat(1, 1, 4))\n",
    "    output_back = G_BA(output)\n",
    "print(f\"Output size: {output.size()} \\t Output Back size: {output_back.size()}\")\n",
    "\n",
    "\n",
    "for i in range(output.size(0)):\n",
    "    plt.plot(output[i, 0, :].numpy())\n",
    "    plt.plot(output_back[i, 0, :].numpy())\n",
    "    plt.plot(dataset_test.data_normal[i, 0, :].numpy())\n",
    "    plt.legend(['Generated', 'Generated Back', 'Original'])\n",
    "    plt.savefig(f'cyber_result/new/forward/output_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "    dist1, cost, acc, path = dtw(output[i,0,:].reshape(-1, 1), dataset_test.data_normal[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    dist2, cost, acc, path = dtw(output_back[i,0,:].reshape(-1, 1), output[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    dist3, cost, acc, path = dtw(output_back[i,0,:].reshape(-1, 1), dataset_test.data_normal[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    res = (dist2+dist3)/dist1\n",
    "    print(\"+\" if res < threshold else \"-\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 144])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.data_abnormal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1, 576])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_abnormal_test = dataset.data_abnormal[:,:,:]\n",
    "data_abnormal_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = G_AB(data_abnormal_test)\n",
    "    output_back = G_BA(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 7.783490175983338\n",
      "+ 5.22026952259301\n",
      "+ 5.554223316149699\n",
      "- 7.704351576312942\n",
      "- 11.423459216250198\n",
      "- 6.643061377670183\n",
      "- 6.643061377670183\n",
      "- 17.984224235383753\n",
      "- 18.353292812651002\n",
      "- 17.89049843925211\n",
      "- 18.05285578440196\n",
      "- 17.480118543201513\n",
      "- 12.972129353480696\n",
      "+ 1.0232251716045897\n",
      "+ 2.069967104175299\n",
      "+ 1.7359055197613948\n",
      "+ 1.2400592506194859\n",
      "+ 2.161298658520614\n",
      "- 21.98135402163749\n",
      "+ 1.3208503536944418\n",
      "+ 4.025003158882967\n",
      "+ 1.200075569396496\n",
      "+ 1.2931424043742938\n",
      "+ 2.9265855922844684\n",
      "+ 1.6697872308373367\n",
      "- 6.447818380783491\n",
      "- 9.704022919896826\n",
      "+ 4.025003158882967\n",
      "+ 1.9377114825577808\n",
      "+ 0.7512348216120813\n",
      "+ 4.871529006170861\n",
      "- 6.890443803395747\n",
      "+ 4.2408844451976275\n"
     ]
    }
   ],
   "source": [
    "for i in range(output.size(0)):\n",
    "    plt.plot(output[i, 0, :].numpy())\n",
    "    plt.plot(output_back[i, 0, :].numpy())\n",
    "    plt.plot(data_abnormal_test[i, 0, :].numpy())\n",
    "    plt.legend(['Generated', 'Generated Back', 'Original'])\n",
    "    plt.savefig(f'cyber_result/detection/output_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "    dist1, cost, acc, path = dtw(output[i,0,:].reshape(-1, 1), data_abnormal_test[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    dist2, cost, acc, path = dtw(output_back[i,0,:].reshape(-1, 1), output[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "    dist3, cost, acc, path = dtw(output_back[i,0,:].reshape(-1, 1), data_abnormal_test[i,0,:].reshape(-1, 1), dist=lambda x, y: np.linalg.norm(x - y, ord=1)) \n",
    "    res = (dist2+dist3)/dist1   \n",
    "    print(\"+\" if res < threshold else \"-\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
